---
title: "STAT_380_Final_Code"
author: "Andrew Bartnikowski, Zachary Brown, Julian Grossman, Rowan Tolfree"
date: "2025-11-26"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Front Matter - Clean Environment, Load Libraries, Read dataset
```{r}
# installs if package(s) are not already installed:
install_check <- function(package) {
  if (!require(package, character.only = TRUE)) {
    install.packages(package, dependencies = TRUE)
  }
  library(package, character.only = TRUE)
}

```

```{r}
# just as a note install_check is a custom function that checks if a package needs to be installed and regardless of that, it loads each library.
install_check("readr")
install_check("tidyr")
install_check("dplyr")
install_check("stringr")
install_check("ggplot2")
install_check("forcats")
install_check("FNN")
install_check("randomForest")
install_check("pROC")
```

Load in our data sets

```{r}
Modes <- read.csv("CODGameModes.csv")
Player1_raw <- read.csv("CODGames_p1_380.csv")
Player2_raw <- read.csv("CODGames_p2_380.csv")
```

## Google Slides Link

<https://docs.google.com/presentation/d/1PNZlMqMhsrZjMR_51fbR-UHyPgB0tzKvTeELMKPCPP8/edit?usp=sharing>

## Task 1 -- Exploratory Analysis

Remove hardcore indicators in a separate column to prepare the data for a join on the COD game modes data. I kept the data for each player seperate foe ease of use when trying to compare insights from each. A joint data set will be made soon below.

```{r}
Player1 <- Player1_raw  %>%
  mutate(Mode = str_replace(GameType, "HC - ", ""))

Player2 <- Player2_raw  %>%
  mutate(Mode = str_replace(GameType, "HC - ", ""))
```

Join each players data with the game modes data so we can answer our research question, "Which game mode is most likely to reach the score limit?".

```{r}
Clean_p1 <- Player1 %>%
  left_join(Modes, by = c("Mode" = "Mode"))

Clean_p2 <- Player2 %>%
  left_join(Modes, by = c("Mode" = "Mode"))
```

Need to be able to identify whether or not score limit has been reached

```{r}
Clean_p1 <- Clean_p1 %>% 
  filter(Score != is.na(Score))%>% 
  separate(Result, into = c("PlayerTeam", "OtherTeam"), sep = "-", convert = TRUE) %>% 
  mutate(MaxScore = pmax(PlayerTeam, OtherTeam),
         ScoreLimitReached = MaxScore == ScoreLimit) 

Clean_p2 <- Clean_p2 %>% 
  filter(Score != is.na(Score)) %>% 
  separate(Result, into = c("PlayerTeam", "OtherTeam"), sep = "-", convert = TRUE) %>% 
  mutate(MaxScore = pmax(PlayerTeam, OtherTeam),
         ScoreLimitReached = MaxScore == ScoreLimit) 
```

Joined the players to make one large data set to more accurately answer our research question for task 1.

```{r}
Joined_players <- bind_rows(Clean_p1, Clean_p2)
```

Create visualization displaying the game modes and the proportion of them reaching the score limit. Simple bar chart to explain this.

```{r}
ggplot(
  data = Joined_players %>%
    group_by(Mode) %>%
    summarise(
      Pct_limit = mean(ScoreLimitReached)
      ),
  mapping = aes(x = Mode, y = Pct_limit)
) + 
  labs(
  title = "Percent of Games per Mode Where Score Limit was Reached",
  x = "Game Mode",
  y = "Percentage of Games Score Limit Reached"
) +
  geom_col(width = 0.5, fill = "lightblue") +
  theme_bw()
```

## Task 2 -- Inference

### Task 2a - Which predictors are associated with the TotalXP?

#### Convert categorical Variables

```{r}
Joined_players2 <- Joined_players %>%
  # Convert categorical variables to factors
  mutate(
    GameType = as.factor(GameType),
    Mode = as.factor(Mode),
    PrimaryWeapon = as.factor(PrimaryWeapon),
    XPType = as.factor(XPType),
    FullPartial = as.factor(FullPartial),
    DidPlayerVote = as.factor(DidPlayerVote),
    ScoreLimitReached = as.factor(ScoreLimitReached)
  )
```

There are two different Double XP + 10%. 517 for one and one for the other. So we will merge those 2 as this is most likely a mistake when imputing the data.

```{r}
Joined_players2 <- Joined_players2 %>%
  mutate(
    XPType = fct_collapse(XPType,
                          "Double XP + 10%" = c("Double XP + 10%", "Double XP + 10% "))
  )
```

#### Find Rows With NA

```{r}
col_NA_totals <- colSums(is.na(Joined_players2))
col_NA_totals
```

#### Multiple Linear Regression

```{r}
lm_xp <- lm(
  TotalXP ~ Eliminations + Deaths + Score + Damage +
            Mode + PrimaryWeapon + XPType +
            FullPartial + DidPlayerVote + ScoreLimitReached,
  data = Joined_players2
)

coef_df <- as.data.frame(summary(lm_xp)$coefficients)

coef_df_p05 <- coef_df %>%
  filter(`Pr(>|t|)`<.05)%>%
  arrange(`Pr(>|t|)`) %>%
  select(Estimate,`Pr(>|t|)`)

coef_df_p1 <- coef_df %>%
  filter(`Pr(>|t|)`<.1) %>%
  arrange(`Pr(>|t|)`) %>%
  select(Estimate,`Pr(>|t|)`)
summary(lm_xp)
```

Due to the large number of missing values in the variables Confirms, Denies, Objectives, ObjectiveKills, Captures, Diffuses, Plants, Detonates, Deposits, Time_Sec, and Time_Min, these variables were excluded from the model to avoid loss of data. After running the multiple linear regression, then looking at the p-values denoted by the Pr(\>\|t\|) column, it tells us which predictors are statistically significant predictors for TotalXP. The predictors that will be deemed statistically significant will have a p-value less than 0.05. The predictors that fit this are: Eliminations, Score, Damage, PrimaryWeaponMilano 821, PrimaryWeaponXM4, and XPTypeDouble XP + 10%. These results indicate that TotalXP is primarily driven by player performance metrics and XP multipliers.

```{r}
coef_df_p1
```

#### Testing Different variables in a single variable linear regression

Looking at the associated P Values associated with the proper t value, it can be seen that the most strongly correlated variable for predicting TotalXP was if a player had Double XP or not. The next two strongest correlated variables were score and Eliminations. We next decided to see what the RMSE would be when we used each of these as a predictor.

```{r}
lm_xpType <- lm(TotalXP ~ XPType, data = Joined_players2)
lm_score <- lm(TotalXP ~ Score, data = Joined_players2)
lm_elims <- lm(TotalXP ~ Eliminations, data = Joined_players2)
lm_t3 <- lm(TotalXP ~ XPType + Eliminations+ Score, data = Joined_players2)

results <- as.data.frame(
  rbind(
    c("XPType",        sqrt(mean(residuals(lm_xpType)^2)), summary(lm_xpType)$r.squared),
    c("Score",         sqrt(mean(residuals(lm_score)^2)),  summary(lm_score)$r.squared),
    c("Eliminations",  sqrt(mean(residuals(lm_elims)^2)),  summary(lm_elims)$r.squared),
    c("Top 3 Vars",    sqrt(mean(residuals(lm_t3)^2)),     summary(lm_t3)$r.squared)
  )
)
colnames(results) <- c("Model", "RMSE", "Multiple R-squared")
results
summary(lm_t3)


```

The XPType variable represents, similar to the intercept, if a value of 7747.5164 should be added to TotalXP having an x value of 1 if a game did have Double XP and 0 if it did not, holding all other variables constant. The eliminations variable represents the increase to TotalXP for each elimination a player earned during a game, holding all other variables constant. The score variable represents the increase in TotalXP for each unit of score earned, holding all other variables constant.

```{r}
ggplot(Joined_players2, aes(x = Eliminations, y = TotalXP)) +
  geom_point(alpha = 0.4, color = "blue") +
  geom_smooth(method = "lm", se = TRUE, color = "red") +
  labs(
    title = "Regression Line: TotalXP ~ Eliminations",
    x = "Eliminations",
    y = "Total XP"
  ) +
  theme_minimal(base_size = 14)
```

```{r}
Joined_players2$pred_t3 <- predict(lm_t3)

ggplot(Joined_players2, aes(x = pred_t3, y = TotalXP)) +
  geom_point(alpha = 0.4, color = "blue") +
  geom_smooth(method = "lm", color = "red") +
  labs(
    title = "Predicted vs Actual TotalXP (Top 3 Model)",
    x = "Predicted TotalXP",
    y = "Actual TotalXP"
  ) +
  theme_minimal(base_size = 14)

```

### Task 2b -Of the predictors associated with the response, select one of the predictors and explain the relationship between the predictor and TotalXP.

```{r}
ggplot(Joined_players2, aes(x = XPType, y = TotalXP)) +
  geom_boxplot(fill = "lightblue") +
  labs(
    title = "Effect of XPType on TotalXP",
    x = "XPType",
    y = "TotalXP"
  )
```

The boxplot clearly shows that matches with Double XP result in much higher TotalXP than standard matches. This confirms the model result that XPType is a strong driver of XP gains.

## Task 3 Prediction

### Research Question: What are the best predictors for classifying game mode?

#### Take only columns that are not game mode unique or we are not interested in. Also selection of only matches the player played fully.

```{r}

Task3_base <- Joined_players2 %>%
  filter(Choice!='')%>%
  filter(FullPartial!='Partial')%>%
  select(
    -any_of(c(
      "Confirms", "Denies", "Objectives", "ObjectiveKills",
      "Captures", "Diffuses", "Plants", "Detonates",
      "Deposits", "Time_Sec", "Time_Min","Map1", "Map2","MapVote",
      "GameType", "Date", "ScoreLimit", "TimeLimit", "MaxScore"
    ))
  ) 
```

#### Perform one-hot encoding and rejoin with numeric values

```{r}
X_task3 <- as.data.frame(model.matrix(
  Mode ~ Choice + PrimaryWeapon + XPType + DidPlayerVote  + ScoreLimitReached ,
  data = Task3_base
)[, -1])

numeric_df <- Task3_base %>%
  select(PlayerTeam,OtherTeam,Eliminations,Deaths,Score,Damage,TotalXP)

X_task3 <- cbind(X_task3,numeric_df)
```

#### Split data into testing and training sets

```{r}
set.seed(123)
n_obs <- nrow(X_task3)
train_idx <- sample(seq_len(n_obs), size = floor(0.7 * n_obs))
test_idx  <- setdiff(seq_len(n_obs), train_idx)

X_train <- X_task3[train_idx, ]
X_test  <- X_task3[test_idx, ]
y_train <- Task3_base$Mode[train_idx]
y_test  <- Task3_base$Mode[test_idx]

```

#### Not Needed

If wanted we could add this to the numeric_df to scale it, those vals are scaleable.

```{r eval=FALSE}
X_train_sc <- scale(X_train)
X_test_sc  <- scale(
  X_test,
  center = attr(X_train_sc, "scaled:center"),
  scale  = attr(X_train_sc, "scaled:scale")
)
```

### Classification Method 1: KNN

```{r}

k_values_knn <- 1:20
knn_results <- data.frame(
k = k_values_knn,
accuracy = rep(NA, length(k_values_knn))
)

for (i in seq_along(k_values_knn)) {
  k_now <- k_values_knn[i]
  knn_fit <- knn(
    train = X_train,
    test  = X_test,
    cl    = y_train,
    k     = k_now
    )
  knn_results$accuracy[i] <- mean(as.character(knn_fit) == as.character(y_test))

}

knn_results

```

```{r}
ggplot(data = knn_results, mapping = aes(x = k, y = accuracy)) +
  geom_line()+
  theme_minimal()

```

Looking at this plot, it can be seen a k of 13 yielded the highest accuracy of 68.8% at classifying the game mode type. An acceptable but not ideal number.

### Classification Method 2: Random Forests

```{r}
rf_fitted <- randomForest(
  x         = X_train,
  y         = y_train, 
  importance=TRUE
)

rf_fitted


rf_pred <- predict(rf_fitted, newdata = X_test)

rf_accuracy <- mean(rf_pred == y_test)
rf_accuracy

plot(rf_fitted)
```

### Classification Method 3: PCA

```{r}
sds <- apply(X_train, 2, sd, na.rm = TRUE)
const_cols <- is.na(sds) | sds == 0
X_train_pca <- X_train[, !const_cols, drop = FALSE]
X_test_pca <- X_test[, !const_cols, drop = FALSE]
pca_fit <- princomp(X_train_pca, cor = TRUE)
summary(pca_fit)
```

```{r}
pve <- pca_fit$sdev^2 / sum(pca_fit$sdev^2)
pve_df <- data.frame(
PC = seq_along(pve),
PVE = pve,
CumPVE = cumsum(pve)
)
ggplot(pve_df, aes(x = PC, y = PVE)) +
geom_line() +
geom_point() +
theme_minimal() +
labs(
title = "Variance Explained",
x = "Principal Component",
y = "Proportion of Variance Explained"
)

```
```{r}
num_pcs <- 13

train_scores_knn <- pca_fit$scores[, 1:num_pcs, drop = FALSE]
test_scores_knn  <- predict(pca_fit, newdata = X_test_pca)[, 1:num_pcs, drop = FALSE]


k_values_knn <- 1:20
knn_results_pca <- data.frame(
k = k_values_knn,
accuracy = rep(NA, length(k_values_knn))
)

for (i in seq_along(k_values_knn)) {
  k_now <- k_values_knn[i]
  knn_fit <- knn(
    train = X_train_pca,
    test  = X_test_pca,
    cl    = y_train,
    k     = k_now
    )
  knn_results_pca$accuracy[i] <- mean(as.character(knn_fit) == as.character(y_test))

}
knn_results_pca
```
```{r}
best_k <- knn_results_pca$k[which.max(knn_results$accuracy)]

pred_test <- knn(
  train = train_scores_knn,
  test  = test_scores_knn,
  cl    = y_train,
  k     = best_k
)
test_plot_df <- data.frame(
  PC1 = test_scores_knn[,1],
  PC2 = test_scores_knn[,2],
  Pred = pred_test
)
ggplot(test_plot_df, aes(PC1, PC2, color = Pred)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm") +
  theme_minimal() +
  labs(
    title = "PC1 vs PC2 Colored by Game Mode Predict",
    x = "Principal Component 1",
    y = "Principal Component 2",
    color = "Game Mode Predict"
    )
```

```{r}
train_scores <- data.frame(
PC1 = pca_fit$scores[, 1],
PC2 = pca_fit$scores[, 2],
Mode = y_train
)
ggplot(train_scores, aes(x = PC1, y = PC2, color = Mode)) +
geom_point(alpha = 0.6) +
theme_minimal() +
labs(
title = "PC1 vs PC2 Colored by Game Mode",
x = "Principal Component 1",
y = "Principal Component 2",
color = "Game Mode"
)
```

This PC1 vs PC2 plot shows each match in the space of the first two principal components, with points colored by game mode. We can see that Hardpoint games tend to cluster on the left side of PC1, while Kill Confirmed and TDM matches are more concentrated toward the center and right, with Domination appearing mostly in the upper-right region but with far fewer observations. There is some visible separation between modes, especially between Hardpoint and the other game types, but there is still a fair amount of overlap. This suggests that the main directions of variation captured by the first two principal components do carry information about game mode, but no single linear boundary in this 2-D PC space can perfectly classify all four modes.

##Other Visualizations and Analysis:
###Mean Decrease Gini (Random Forest):

```{r}
gini_importance <- importance(rf_fitted) 
importance_df <- as.data.frame(gini_importance) 
importance_df[order(importance_df$MeanDecreaseGini, decreasing = TRUE),]
```
plot:
```{r}
impplot <- varImpPlot(rf_fitted, n.var=min(10, nrow(rf_fitted$importance)))
```

### AUC curves:
```{r}
for (x in 1:4) {
  rf_probs <- predict(rf_fitted,  type="prob")[, x]
  rocobj <- roc(y_train, rf_probs)
  plot(rocobj)
  auc(rocobj)
}
```
```{r}
rf_prob_mat <- predict(rf_fitted, type = "prob")
cls_rf <- colnames(rf_prob_mat)

par(mfrow = c(2, 2))

auc_rf <- numeric(length(cls_rf))
names(auc_rf) <- cls_rf

for (pos_rf in cls_rf) {
  y_bin_rf <- as.integer(as.character(y_train) == pos_rf)
  roc_rf <- roc(response = y_bin_rf, predictor = rf_prob_mat[, pos_rf], quiet = TRUE)
  plot(roc_rf, main = paste("ROC:", pos_rf), print.auc = TRUE)
  auc_rf[pos_rf] <- as.numeric(auc(roc_rf))
}

par(mfrow = c(1, 1))
auc_rf
```
```{r}

lvl_ovr <- levels(factor(y_train))

par(mfrow = c(2, 2))

auc_ovr_vec <- numeric(length(lvl_ovr))
names(auc_ovr_vec) <- lvl_ovr

for (pos_ovr in lvl_ovr) {
  lab_tr_bin_ovr <- factor(ifelse(y_train == pos_ovr, pos_ovr, "rest"), levels = c("rest", pos_ovr))
  lab_te_bin_ovr <- factor(ifelse(y_test  == pos_ovr, pos_ovr, "rest"), levels = c("rest", pos_ovr))

  pred_bin_ovr <- knn(train = X_train, test = X_test, cl = lab_tr_bin_ovr, k = 13, prob = TRUE)
  pwin_ovr <- attr(pred_bin_ovr, "prob")
  ppos_ovr <- ifelse(pred_bin_ovr == pos_ovr, pwin_ovr, 1 - pwin_ovr)

  roc_obj_ovr <- roc(response = lab_te_bin_ovr, predictor = ppos_ovr, levels = c("rest", pos_ovr), direction = "<")
  plot(roc_obj_ovr, main = paste("ROC", pos_ovr), print.auc = TRUE)

  auc_ovr_vec[pos_ovr] <- as.numeric(auc(roc_obj_ovr))
}

par(mfrow = c(1, 1))
auc_ovr_vec

```
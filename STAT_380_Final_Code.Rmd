---
title: "STAT_380_Final_Code"
author: "Andrew Bartnikowski, Zachary Brown, Julian Grossman, Rowan Tolfree"
date: "2025-11-26"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Front Matter - Clean Environment, Load Libraries, Read dataset

```{r}
rm(list = ls())
library(readr)
library(tidyr)
library(dplyr)
library(stringr)
library(ggplot2)
library(forcats)
library(FNN)
library(randomForest)
```

Load in our data sets
```{r}
Modes <- read.csv("CODGameModes.csv")
Player1_raw <- read.csv("CODGames_p1_380.csv")
Player2_raw <- read.csv("CODGames_p2_380.csv")
```
## Google Slides Link
https://docs.google.com/presentation/d/1PNZlMqMhsrZjMR_51fbR-UHyPgB0tzKvTeELMKPCPP8/edit?usp=sharing 

## Task 1 -- Exploratory Analysis

Remove hardcore indicators in a separate column to prepare the data for a join on the COD game modes data. I kept the data for each player seperate foe ease of use when trying to compare insights from each. A joint data set will be made soon below.
```{r}
Player1 <- Player1_raw  %>%
  mutate(Mode = str_replace(GameType, "HC - ", ""))

Player2 <- Player2_raw  %>%
  mutate(Mode = str_replace(GameType, "HC - ", ""))
```

Join each players data with the game modes data so we can answer our research question, "Which game mode is most likely to reach the score limit?".
```{r}
Clean_p1 <- Player1 %>%
  left_join(Modes, by = c("Mode" = "Mode"))

Clean_p2 <- Player2 %>%
  left_join(Modes, by = c("Mode" = "Mode"))
```


Need to be able to identify whether or not score limit has been reached
```{r}
Clean_p1 <- Clean_p1 %>% 
  filter(Score != is.na(Score))%>% 
  separate(Result, into = c("PlayerTeam", "OtherTeam"), sep = "-", convert = TRUE) %>% 
  mutate(MaxScore = pmax(PlayerTeam, OtherTeam),
         ScoreLimitReached = MaxScore == ScoreLimit) 

Clean_p2 <- Clean_p2 %>% 
  filter(Score != is.na(Score)) %>% 
  separate(Result, into = c("PlayerTeam", "OtherTeam"), sep = "-", convert = TRUE) %>% 
  mutate(MaxScore = pmax(PlayerTeam, OtherTeam),
         ScoreLimitReached = MaxScore == ScoreLimit) 
```


Joined the players to make one large data set to more accurately answer our research question for task 1.
```{r}
Joined_players <- bind_rows(Clean_p1, Clean_p2)
```

Create visualization displaying the game modes and the proportion of them reaching the score limit. Simple bar chart to explain this.
```{r}
ggplot(
  data = Joined_players %>%
    group_by(Mode) %>%
    summarise(
      Pct_limit = mean(ScoreLimitReached)
      ),
  mapping = aes(x = Mode, y = Pct_limit)
) + 
  labs(
  title = "Percent of Games per Mode Where Score Limit was Reached",
  x = "Game Mode",
  y = "Percentage of Games Score Limit Reached"
) +
  geom_col(width = 0.5, fill = "lightblue") +
  theme_bw()
```

## Task 2 -- Inference

### Task 2a - Which predictors are associated with the TotalXP?

#### Convert categorical Variables
```{r}
Joined_players2 <- Joined_players %>%
  # Convert categorical variables to factors
  mutate(
    GameType = as.factor(GameType),
    Mode = as.factor(Mode),
    PrimaryWeapon = as.factor(PrimaryWeapon),
    XPType = as.factor(XPType),
    FullPartial = as.factor(FullPartial),
    DidPlayerVote = as.factor(DidPlayerVote),
    ScoreLimitReached = as.factor(ScoreLimitReached)
  )
```

There are two different Double XP + 10%. 517 for one and one for the other. So we will merge those 2 as this is most likely a mistake when imputing the data.
```{r}
Joined_players2 <- Joined_players2 %>%
  mutate(
    XPType = fct_collapse(XPType,
                          "Double XP + 10%" = c("Double XP + 10%", "Double XP + 10% "))
  )
```

#### Find Rows With NA
```{r}
col_NA_totals <- colSums(is.na(Joined_players2))
col_NA_totals
```

#### Multiple Linear Regression
```{r}
lm_xp <- lm(
  TotalXP ~ Eliminations + Deaths + Score + Damage +
            Mode + PrimaryWeapon + XPType +
            FullPartial + DidPlayerVote + ScoreLimitReached,
  data = Joined_players2
)

coef_df <- as.data.frame(summary(lm_xp)$coefficients)

coef_df_p05 <- coef_df %>%
  filter(`Pr(>|t|)`<.05)%>%
  arrange(`Pr(>|t|)`) %>%
  select(Estimate,`Pr(>|t|)`)

coef_df_p1 <- coef_df %>%
  filter(`Pr(>|t|)`<.1) %>%
  arrange(`Pr(>|t|)`) %>%
  select(Estimate,`Pr(>|t|)`)
summary(lm_xp)
```

Due to the large number of missing values in the variables Confirms, Denies, Objectives, ObjectiveKills, Captures, Diffuses, Plants, Detonates, Deposits, Time_Sec, and Time_Min, these variables were excluded from the model to avoid loss of data. After running the multiple linear regression, then looking at the p-values denoted by the Pr(>|t|) column, it tells us which predictors are statistically significant predictors for TotalXP. The predictors that will be deemed statistically significant will have a p-value less than 0.05. The predictors that fit this are: Eliminations, Score, Damage, PrimaryWeaponMilano 821, PrimaryWeaponXM4, and XPTypeDouble XP + 10%. These results indicate that TotalXP is primarily driven by player performance metrics and XP multipliers.

```{r}
coef_df_p1
```
#### Testing Different variables in a  single variable linear regression
Looking at the associated P Values associated with the proper t value, it can be seen that the most strongly correlated variable for predicting TotalXP was if a player had Double XP or not. The next two strongest correlated variables were score and Eliminations. We next decided to see what the RMSE would be when we used each of these as a predictor.

```{r}
lm_xpType <- lm(TotalXP ~ XPType, data = Joined_players2)
lm_score <- lm(TotalXP ~ Score, data = Joined_players2)
lm_elims <- lm(TotalXP ~ Eliminations, data = Joined_players2)
lm_t3 <- lm(TotalXP ~ XPType + Eliminations+ Score, data = Joined_players2)

results <- as.data.frame(
  rbind(
    c("XPType",        sqrt(mean(residuals(lm_xpType)^2)), summary(lm_xpType)$r.squared),
    c("Score",         sqrt(mean(residuals(lm_score)^2)),  summary(lm_score)$r.squared),
    c("Eliminations",  sqrt(mean(residuals(lm_elims)^2)),  summary(lm_elims)$r.squared),
    c("Top 3 Vars",    sqrt(mean(residuals(lm_t3)^2)),     summary(lm_t3)$r.squared)
  )
)
colnames(results) <- c("Model", "RMSE", "Multiple R-squared")
results
summary(lm_t3)


```
The XPType variable represents, similar to the intercept, if a value of 7747.5164 should be added to TotalXP having an x value of 1 if a game did have Double XP and 0 if it did not, holding all other variables constant. The eliminations variable represents the increase to TotalXP for each elimination a player earned during a game, holding all other variables constant. The score variable represents the increase in TotalXP for each unit of score earned, holding all other variables constant.

```{r}
ggplot(Joined_players2, aes(x = Eliminations, y = TotalXP)) +
  geom_point(alpha = 0.4, color = "blue") +
  geom_smooth(method = "lm", se = TRUE, color = "red") +
  labs(
    title = "Regression Line: TotalXP ~ Eliminations",
    x = "Eliminations",
    y = "Total XP"
  ) +
  theme_minimal(base_size = 14)
```
```{r}
Joined_players2$pred_t3 <- predict(lm_t3)

ggplot(Joined_players2, aes(x = pred_t3, y = TotalXP)) +
  geom_point(alpha = 0.4, color = "blue") +
  geom_smooth(method = "lm", color = "red") +
  labs(
    title = "Predicted vs Actual TotalXP (Top 3 Model)",
    x = "Predicted TotalXP",
    y = "Actual TotalXP"
  ) +
  theme_minimal(base_size = 14)

```

### Task 2b -Of the predictors associated with the response, select one of the predictors and explain the relationship between the predictor and TotalXP.
```{r}
ggplot(Joined_players2, aes(x = XPType, y = TotalXP)) +
  geom_boxplot(fill = "lightblue") +
  labs(
    title = "Effect of XPType on TotalXP",
    x = "XPType",
    y = "TotalXP"
  )
```

The boxplot clearly shows that matches with Double XP result in much higher TotalXP than standard matches. This confirms the model result that XPType is a strong driver of XP gains.

## Task 3 Prediction
### Research Question: What are the best predictors for classifying game mode?

#### Take only columns that are not game mode unique or we are not interested in. Also selection of only matches the player played fully.
```{r}

Task3_base <- Joined_players2 %>%
  filter(Choice!='')%>%
  filter(FullPartial!='Partial')%>%
  select(
    -any_of(c(
      "Confirms", "Denies", "Objectives", "ObjectiveKills",
      "Captures", "Diffuses", "Plants", "Detonates",
      "Deposits", "Time_Sec", "Time_Min","Map1", "Map2","MapVote",
      "GameType", "Date", "ScoreLimit", "TimeLimit", "MaxScore"
    ))
  ) 
```

#### Perform one-hot encoding and rejoin with numeric values
```{r}
X_task3 <- as.data.frame(model.matrix(
  Mode ~ Choice + PrimaryWeapon + XPType + DidPlayerVote  + ScoreLimitReached ,
  data = Task3_base
)[, -1])

numeric_df <- Task3_base %>%
  select(PlayerTeam,OtherTeam,Eliminations,Deaths,Score,Damage,TotalXP)

X_task3 <- cbind(X_task3,numeric_df)
```

#### Split data into testing and training sets
```{r}
set.seed(123)
n_obs <- nrow(X_task3)
train_idx <- sample(seq_len(n_obs), size = floor(0.7 * n_obs))
test_idx  <- setdiff(seq_len(n_obs), train_idx)

X_train <- X_task3[train_idx, ]
X_test  <- X_task3[test_idx, ]
y_train <- Task3_base$Mode[train_idx]
y_test  <- Task3_base$Mode[test_idx]

```


#### Not Needed
If wanted we could add this to the numeric_df to scale it, those vals are scaleable. 
```{r eval=FALSE}
X_train_sc <- scale(X_train)
X_test_sc  <- scale(
  X_test,
  center = attr(X_train_sc, "scaled:center"),
  scale  = attr(X_train_sc, "scaled:scale")
)
```

### Classification Method 1: KNN
```{r}

k_values_knn <- 1:20
knn_results <- data.frame(
k = k_values_knn,
accuracy = rep(NA, length(k_values_knn))
)

for (i in seq_along(k_values_knn)) {
  k_now <- k_values_knn[i]
  knn_fit <- knn(
    train = X_train,
    test  = X_test,
    cl    = y_train,
    k     = k_now
    )
  knn_results$accuracy[i] <- mean(as.character(knn_fit) == as.character(y_test))

}

knn_results

```
```{r}
ggplot(data = knn_results, mapping = aes(x = k, y = accuracy)) +
  geom_line()+
  theme_minimal()

```
Looking at this plot, it can be seen a k of 13 yielded the highest accuracy of 68.8% at classifying the game mode type. An acceptable but not ideal number. 

### Classification Method 2: Random Forests
```{r}
rf_fitted <- randomForest(
  x         = X_train,
  y         = y_train
)

rf_fitted


rf_pred <- predict(rf_fitted, newdata = X_test)

rf_accuracy <- mean(rf_pred == y_test)
rf_accuracy

plot(rf_fitted)
```

### Classification Method 3: PCA
```{r}
sds <- apply(X_train, 2, sd, na.rm = TRUE)
const_cols <- is.na(sds) | sds == 0
X_train_pca <- X_train[, !const_cols, drop = FALSE]
pca_fit <- princomp(X_train_pca, cor = TRUE)
summary(pca_fit)
``` 
```{r}
pve <- pca_fit$sdev^2 / sum(pca_fit$sdev^2)
pve_df <- data.frame(
PC = seq_along(pve),
PVE = pve,
CumPVE = cumsum(pve)
)
ggplot(pve_df, aes(x = PC, y = PVE)) +
geom_line() +
geom_point() +
theme_minimal() +
labs(
title = "Variance Explained",
x = "Principal Component",
y = "Proportion of Variance Explained"
)

```
Writing
ggplot(pca_knn_results, aes(x = num_pcs, y = accuracy)) +
geom_line() +
theme_minimal() +
labs(
title = "KNN Accuracy vs. Number of Principal Components (PCA via princomp)",
x = "Number of Principal Components",
y = "Classification Accuracy"
)

You said:
do the same thing and use the same type of sentences and make a visual just like we did for ken and random forest
ChatGPT said:
Writing
sds <- apply(X_train, 2, sd, na.rm = TRUE)
const_cols <- is.na(sds) | sds == 0
X_train_pca <- X_train[, !const_cols, drop = FALSE]
X_test_pca <- X_test[, !const_cols, drop = FALSE]

pca_fit <- princomp(X_train_pca, cor = TRUE)

train_pcs <- predict(pca_fit, newdata = X_train_pca)
test_pcs <- predict(pca_fit, newdata = X_test_pca)

max_pc <- min(20, ncol(train_pcs))
pc_values <- 1

pca_knn_results <- data.frame(
num_pcs = pc_values,
accuracy = rep(NA_real_, length(pc_values))
)

for (i in seq_along(pc_values)) {
d_now <- pc_values[i]
knn_pca_fit <- knn(
train = train_pcs[, 1, drop = FALSE],
test = test_pcs[, 1, drop = FALSE],
cl = y_train,
k = 13
)
pca_knn_results$accuracy[i] <- mean(as.character(knn_pca_fit) == as.character(y_test))
}

pca_knn_results

best_row <- pca_knn_results[which.max(pca_knn_results$accuracy), ]
best_row

cat(
"Using PCA + KNN (k = 13), the best accuracy was",
round(best_row$accuracy * 100, 1), "% with",
best_row$num_pcs, "principal components.\n"
)

Writing
ggplot(pca_knn_results, aes(x = num_pcs, y = accuracy)) +
geom_line() +
geom_point() +
theme_minimal() +
labs(
title = "PCA + KNN: Accuracy vs Number of Principal Components",
x = "Number of Principal Components",
y = "Classification Accuracy"
)

You said:
ok but in between the r code you need explanations this is specifically for explaining the visuals so only once I want just the r code and then sentences where the should be
ChatGPT said:

Thought for 8s
Classification Method 3: PCA
Writing
sds <- apply(X_train, 2, sd, na.rm = TRUE)
const_cols <- is.na(sds) | sds == 0
X_train_pca <- X_train[, !const_cols, drop = FALSE]
X_test_pca <- X_test[, !const_cols, drop = FALSE]

pca_fit <- princomp(X_train_pca, cor = TRUE)

train_pcs <- predict(pca_fit, newdata = X_train_pca)
test_pcs <- predict(pca_fit, newdata = X_test_pca)

max_pc <- min(20, ncol(train_pcs))
pc_values <- 1

pca_knn_results <- data.frame(
num_pcs = pc_values,
accuracy = rep(NA_real_, length(pc_values))
)

for (i in seq_along(pc_values)) {
d_now <- pc_values[i]
knn_pca_fit <- knn(
train = train_pcs[, 1, drop = FALSE],
test = test_pcs[, 1, drop = FALSE],
cl = y_train,
k = 13
)
pca_knn_results$accuracy[i] <- mean(as.character(knn_pca_fit) == as.character(y_test))
}

pca_knn_results

best_row <- pca_knn_results[which.max(pca_knn_results$accuracy), ]
best_row

cat(
"Using PCA + KNN (k = 13), the best accuracy was",
round(best_row$accuracy * 100, 1), "% with",
best_row$num_pcs, "principal components.\n"
)

Using PCA as a preprocessing step, we project the predictors onto a lower-dimensional set of principal components and then run KNN with k = 13 on these PCs. The table and printed sentence above report the classification accuracy for each number of principal components and identify which dimension gives the best overall accuracy for predicting game mode.
Writing
ggplot(pca_knn_results, aes(x = num_pcs, y = accuracy)) +
geom_line() +
geom_point() +
theme_minimal() +
labs(
title = "PCA + KNN: Accuracy vs Number of Principal Components",
x = "Number of Principal Components",
y = "Classification Accuracy"
)

This plot shows how classification accuracy changes as we increase the number of principal components used in the PCA + KNN model. We look for the peak of this curve to choose a PCA dimension that balances model performance with a simpler, lower-dimensional representation of the original COD game data.
You said:
isn't pea its own method?
ChatGPT said:
Yeah, good catch — this is a subtle thing.
PCA is its own method, but it’s:

Unsupervised
A dimensionality reduction / feature extraction technique
Not a classifier by itself (it doesn’t output class labels, just transformed features)
So in what we just coded, the classification method is really:
“PCA + KNN” (PCA for dimension reduction, then KNN as the actual classifier)
For your write-up / slides, I’d label it something like:
Classification Method 3: PCA + KNN
And describe it in a sentence like:
“For our third method, we first applied PCA to reduce the dimensionality of the predictors, then used KNN with k = 13 on the principal components to classify game mode.”
That way you’re being accurate: PCA is a separate statistical method, but here you’re using it as a preprocessing step inside a classification pipeline.
You said:
was it not supposed to be 3 individual methods on there own?
ChatGPT said:

Thought for 23s
Yeah, if the instructions said something like “try three different classification methods,” then strictly speaking they probably meant:
Method 1: one classifier (e.g., KNN)
Method 2: a different classifier (e.g., Random Forest)
Method 3: another different classifier (e.g., Decision Tree, SVM, Naive Bayes, Multinomial Logistic Regression, etc.)
What we did with PCA + KNN is:
PCA = unsupervised dimensionality reduction
KNN = the actual classifier
So Method 3 is still using KNN as the decision rule, just on transformed features. Many instructors would view that as a variation of KNN, not a completely separate classification method.
If you want to be totally safe for grading, I’d do this:

Keep Method 1: KNN
Keep Method 2: Random Forest
Replace Method 3 with a clearly different classifier, like:
Classification Tree (rpart), or
Multinomial Logistic Regression (nnet::multinom), or
Naive Bayes (e1071::naiveBayes)
Then describe and visualize it in the same style (“we trained X model, got Y accuracy, here’s the plot showing …”). If you want, I can rewrite Method 3 as, say, a classification tree with R code + matching explanation sentences.
You said:
no just PCA
ChatGPT said:

Thought for 24s
### Classification Method 3: PCA
Writing
Remove constant / zero-variance columns before PCA
sds <- apply(X_train, 2, sd, na.rm = TRUE)
const_cols <- is.na(sds) | sds == 0
X_train_pca <- X_train[, !const_cols, drop = FALSE]
PCA on standardized predictors (cor = TRUE uses the correlation matrix)
pca_fit <- princomp(X_train_pca, cor = TRUE)
summary(pca_fit)

Here we apply PCA to the standardized predictors used in our classification models. The summary output reports how much variance each principal component explains and helps us see how quickly the total variance is captured as we add more components.
Writing
Scree plot: proportion of variance explained by each PC
pve <- pca_fit$sdev^2 / sum(pca_fit$sdev^2)
pve_df <- data.frame(
PC = seq_along(pve),
PVE = pve,
CumPVE = cumsum(pve)
)
ggplot(pve_df, aes(x = PC, y = PVE)) +
geom_line() +
geom_point() +
theme_minimal() +
labs(
title = "Scree Plot: Variance Explained by Principal Components",
x = "Principal Component",
y = "Proportion of Variance Explained"
)

This scree plot shows how much variance each principal component explains. We look for where the curve levels off to identify a small number of components that still capture most of the variability in the COD match data.
Writing
PC1 vs PC2 colored by game mode (using training data)
train_scores <- data.frame(
PC1 = pca_fit$scores[, 1],
PC2 = pca_fit$scores[, 2],
Mode = y_train
)
ggplot(train_scores, aes(x = PC1, y = PC2, color = Mode)) +
geom_point(alpha = 0.6) +
theme_minimal() +
labs(
title = "PC1 vs PC2 Colored by Game Mode",
x = "Principal Component 1",
y = "Principal Component 2",
color = "Game Mode"
)

This plot shows the first two principal components with points colored by game mode. If modes form visible clusters or separation in this PC space, it suggests that the main directions of variation in the predictors are related to differences between game modes.
You said:
its the same question for all answered through using three different classifications methods individually the last one is PCA
ChatGPT said:

Thought for 24s
Classification Method 3: PCA
Writing
Remove constant / zero-variance columns before PCA
sds <- apply(X_train, 2, sd, na.rm = TRUE)
const_cols <- is.na(sds) | sds == 0
X_train_pca <- X_train[, !const_cols, drop = FALSE]
PCA on standardized predictors (cor = TRUE uses the correlation matrix)
pca_fit <- princomp(X_train_pca, cor = TRUE)
summary(pca_fit)

Here we apply PCA to the predictors used in our classification models. The summary output shows how much variance each principal component explains and tells us how quickly we capture the overall variation with a small number of components. This helps answer our question by showing which directions (combinations of variables) carry most of the information useful for separating game modes.
Writing
Scree plot: proportion of variance explained by each PC
pve <- pca_fit$sdev^2 / sum(pca_fit$sdev^2)
pve_df <- data.frame(
PC = seq_along(pve),
PVE = pve,
CumPVE = cumsum(pve)
)
ggplot(pve_df, aes(x = PC, y = PVE)) +
geom_line() +
geom_point() +
theme_minimal() +
labs(
title = "Scree Plot: Variance Explained by Principal Components",
x = "Principal Component",
y = "Proportion of Variance Explained"
)

This scree plot shows how much variance each principal component explains. We look for where the curve begins to flatten out; the components before this “elbow” are the most important directions. These top components summarize the main structure in the data and therefore highlight which combinations of predictors matter most for distinguishing between game modes.
Writing
PC1 vs PC2 colored by game mode (training data)
train_scores <- data.frame(
PC1 = pca_fit$scores[, 1],
PC2 = pca_fit$scores[, 2],
Mode = y_train
)
ggplot(train_scores, aes(x = PC1, y = PC2, color = Mode)) +
geom_point(alpha = 0.6) +
theme_minimal() +
labs(
title = "PC1 vs PC2 Colored by Game Mode",
x = "Principal Component 1",
y = "Principal Component 2",
color = "Game Mode"
)

This scree plot shows that the first principal component explains a little over 6% of the total variance, the second explains a bit under 4%, and then the remaining components each contribute around 2% or less. There is a small “elbow” in the curve after the first few components, but no single component dominates the variation. This suggests that information useful for distinguishing game modes is spread across many different combinations of variables rather than being captured by just one or two very strong directions in the data
```{r}
train_scores <- data.frame(
PC1 = pca_fit$scores[, 1],
PC2 = pca_fit$scores[, 2],
Mode = y_train
)
ggplot(train_scores, aes(x = PC1, y = PC2, color = Mode)) +
geom_point(alpha = 0.6) +
theme_minimal() +
labs(
title = "PC1 vs PC2 Colored by Game Mode",
x = "Principal Component 1",
y = "Principal Component 2",
color = "Game Mode"
)
```
This PC1 vs PC2 plot shows each match in the space of the first two principal components, with points colored by game mode. We can see that Hardpoint games tend to cluster on the left side of PC1, while Kill Confirmed and TDM matches are more concentrated toward the center and right, with Domination appearing mostly in the upper-right region but with far fewer observations. There is some visible separation between modes, especially between Hardpoint and the other game types, but there is still a fair amount of overlap. This suggests that the main directions of variation captured by the first two principal components do carry information about game mode, but no single linear boundary in this 2-D PC space can perfectly classify all four modes.